{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas numpy scipy matplotlib plotly seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from scipy.optimize import fsolve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# constants\n",
    "AU = 1.496e11  # 1 AU in meters\n",
    "mu = 1.32712440018e20  # Gravitational parameter for Sun (m^3/s^2)\n",
    "earth_a = 1.0 * AU  # Earth's semi-major axis (1 AU)\n",
    "earth_e = 0.0167  # Earth's eccentricity (small, almost circular orbit)\n",
    "earth_epoch = 2459000.5  # Arbitrary epoch for Earth\n",
    "earth_omega = 102.937  # Argument of perihelion for Earth (degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file with object designations\n",
    "file_path = 'cneos_sentry_summary_data.csv'   #dataset taken from NASA CNEOS website\n",
    "data = pd.read_csv(file_path)\n",
    "data.columns = data.columns.str.strip()\n",
    "data['Object Designation'] = data['Object Designation'].str.replace(r'^\\(|\\)$', '', regex=True)\n",
    "\n",
    "# Function to modify the object designations\n",
    "def clean_object_designation(designation):\n",
    "    # Remove extra spaces\n",
    "    designation = ' '.join(designation.split())\n",
    "    # Replace space after year with \"%\"\n",
    "    parts = designation.split(\" \")\n",
    "    \n",
    "    # Check if the first part is a year and if so, replace the following space\n",
    "    if len(parts) > 1 and parts[0].isdigit() and len(parts[0]) == 4:  # Year check\n",
    "        designation = parts[0] + \"%20\" + \" \".join(parts[1:])  # Rejoin with `%`\n",
    "    return designation\n",
    "\n",
    "# Apply the function to the Object Designation column\n",
    "data['Object Designation'] = data['Object Designation'].apply(clean_object_designation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate object details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_orbital_elements(object_designation):\n",
    "    url = f\"https://ssd-api.jpl.nasa.gov/sbdb.api?sstr={object_designation}&full-prec=true\"\n",
    "    response = requests.get(url)\n",
    "        \n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        # Check if 'orbit' exists \n",
    "        if 'orbit' in data and isinstance(data['orbit']['elements'], list):\n",
    "            elements = data['orbit']['elements']\n",
    "            print(f\"Elements for {object_designation}: {elements}\")  # Debugging line\n",
    "            \n",
    "            orbital_data = {elem['label']: elem['value'] for elem in elements if 'label' in elem and 'value' in elem}\n",
    "            \n",
    "            # Print the extracted orbital data for debugging\n",
    "            print(f\"Orbital data extracted for {object_designation}: {orbital_data}\")  \n",
    "            \n",
    "            # Extracting orbital data \n",
    "            orbital_data = {elem['label']: elem['value'] for elem in elements if 'label' in elem and 'value' in elem}\n",
    "\n",
    "            # return the correct keys\n",
    "            return {\n",
    "                'a': orbital_data.get('a'),        # Semi-major axis\n",
    "                'e': orbital_data.get('e'),        # Eccentricity\n",
    "                'i': orbital_data.get('i'),        # Inclination\n",
    "                'Omega': orbital_data.get('node'),  # Longitude of ascending node\n",
    "                'omega': orbital_data.get('peri'),   # Argument of perihelion\n",
    "                'M0': orbital_data.get('M'),       # Mean anomaly\n",
    "                'epoch': data['orbit'].get('epoch')  # Epoch from the orbit data\n",
    "            }\n",
    "\n",
    "    else:\n",
    "        print(f\"Error fetching data for {object_designation}: Status code {response.status_code}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for orbital elements in the DataFrame\n",
    "data['a'] = pd.NA\n",
    "data['e'] = pd.NA\n",
    "data['i'] = pd.NA\n",
    "data['Omega'] = pd.NA\n",
    "data['omega'] = pd.NA\n",
    "data['M0'] = pd.NA\n",
    "data['epoch'] = pd.NA\n",
    "\n",
    "# Loop over each object and fetch its orbital elements\n",
    "# takes atmost 15 mins\n",
    "for index, row in data.iterrows():\n",
    "    object_designation = row['Object Designation']\n",
    "    orbital_data = fetch_orbital_elements(object_designation)\n",
    "\n",
    "    if orbital_data:\n",
    "        data.at[index, 'a'] = float(orbital_data['a'])\n",
    "        data.at[index, 'e'] = float(orbital_data['e'])\n",
    "        data.at[index, 'i'] = float(orbital_data['i'])\n",
    "        data.at[index, 'Omega'] = float(orbital_data['Omega'])\n",
    "        data.at[index, 'omega'] = float(orbital_data['omega'])\n",
    "        data.at[index, 'M0'] = float(orbital_data['M0'])\n",
    "        data.at[index, 'epoch'] = float(orbital_data['epoch'])\n",
    "    else:\n",
    "        print(f\"No orbital data found for {object_designation}\")\n",
    "\n",
    "data = data.dropna(subset=['a', 'e', 'i', 'Omega', 'omega', 'M0', 'epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute position based on orbital elements\n",
    "def compute_position(a, e, i, Omega, omega, M0, epoch, t):\n",
    "    # Constants and conversions \n",
    "    i = np.radians(i)\n",
    "    Omega = np.radians(Omega)\n",
    "    omega = np.radians(omega)\n",
    "    M0 = np.radians(M0)\n",
    "\n",
    "    # Mean motion\n",
    "    n = np.sqrt(mu / a**3)\n",
    "    dt = (t - epoch) * 86400  # Time difference in seconds\n",
    "    M = M0 + n * dt  # Mean anomaly\n",
    "\n",
    "    # Initial guess for eccentric anomaly\n",
    "    E0 = M if e < 1 else np.pi  # For hyperbolic orbits, start at pi\n",
    "    E = E0\n",
    "\n",
    "    for _ in range(10):  # Maximum iterations\n",
    "        E = E - (E - e * np.sin(E) - M) / (1 - e * np.cos(E))\n",
    "        # Break if the change is small enough\n",
    "        if abs(E - (E0 if e < 1 else np.pi)) < 1e-10:\n",
    "            break\n",
    "\n",
    "    # True anomaly\n",
    "    true_anomaly = 2 * np.arctan2(np.sqrt(1 + e) * np.sin(E / 2), np.sqrt(1 - e) * np.cos(E / 2))\n",
    "\n",
    "    # Distance to Sun\n",
    "    r = a * (1 - e * np.cos(E))\n",
    "\n",
    "    # 3D coordinates in the orbital plane\n",
    "    x_prime = r * np.cos(true_anomaly)\n",
    "    y_prime = r * np.sin(true_anomaly)\n",
    "\n",
    "    # Convert to 3D space using the orbital elements\n",
    "    cos_Omega = np.cos(Omega)\n",
    "    sin_Omega = np.sin(Omega)\n",
    "    cos_i = np.cos(i)\n",
    "    sin_i = np.sin(i)\n",
    "    cos_omega = np.cos(omega)\n",
    "    sin_omega = np.sin(omega)\n",
    "\n",
    "    x = (cos_Omega * cos_omega - sin_Omega * sin_omega * cos_i) * x_prime + (-cos_Omega * sin_omega - sin_Omega * cos_omega * cos_i) * y_prime\n",
    "    y = (sin_Omega * cos_omega + cos_Omega * sin_omega * cos_i) * x_prime + (-sin_Omega * sin_omega + cos_Omega * cos_omega * cos_i) * y_prime\n",
    "    z = (sin_i * sin_omega) * x_prime + (sin_i * cos_omega) * y_prime\n",
    "\n",
    "    return np.array([x, y, z])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute Earth's position\n",
    "def compute_earth_position(t):\n",
    "    # Mean anomaly for Earth (radians)\n",
    "    M = (2 * np.pi / 365.25) * (t - 2451545)  # M = 2Ï€/T * (t - epoch) \n",
    "    E0 = M  # Initial guess for E\n",
    "    # Kepler's equation to find E\n",
    "    def kepler(E, M):\n",
    "        return E - np.sin(E) - M\n",
    "    E = fsolve(kepler, E0, args=(M,))[0]  \n",
    "\n",
    "    # Calculate true anomaly\n",
    "    true_anomaly = 2 * np.arctan2(np.sqrt(1 + 0.0167) * np.sin(E / 2), np.sqrt(1 - 0.0167) * np.cos(E / 2))\n",
    "\n",
    "    # Distance to the Sun\n",
    "    r = AU  # Average distance from Earth to Sun (1 AU)\n",
    "\n",
    "    # 3D coordinates in the orbital plane\n",
    "    x = r * np.cos(true_anomaly)\n",
    "    y = r * np.sin(true_anomaly)\n",
    "    z = 0  \n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "t = 2459005.5  \n",
    "earth_position = compute_earth_position(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate relative positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the updated DataFrame and compute relative position to Earth\n",
    "relative_positions = []  # To store relative positions\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    try:\n",
    "        a = row['a'] * AU  # AU to meters\n",
    "        e = row['e']\n",
    "        i = row['i']\n",
    "        Omega = row['Omega']\n",
    "        omega = row['omega']\n",
    "        M0 = row['M0']\n",
    "        epoch = row['epoch']\n",
    "        \n",
    "        # Compute asteroid position\n",
    "        asteroid_position = compute_position(a, e, i, Omega, omega, M0, epoch, t)\n",
    "        \n",
    "        # Calculate relative position to Earth\n",
    "        relative_position = asteroid_position - earth_position\n",
    "        relative_positions.append(relative_position)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"Error at index {index}: {err}\")\n",
    "\n",
    "relative_positions = np.array(relative_positions)\n",
    "\n",
    "# Add the relative positions to the DataFrame\n",
    "data['relative_position_x'] = relative_positions[:, 0]  # x-coordinates\n",
    "data['relative_position_y'] = relative_positions[:, 1]  # y-coordinates\n",
    "data['relative_position_z'] = relative_positions[:, 2]  # z-coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Re-Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[data.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.strip()\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 10'],axis=1,inplace=True)\n",
    "data[['Year Start', 'Year End']] = data['Year Range'].str.split(\"-\", n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()    # Dropping the missing values.\n",
    "data.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Year Range'], axis=1, inplace=True)\n",
    "numeric_columns = list(data.select_dtypes('number'))\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about a minute\n",
    "plt.figure(figsize=(25, 25))\n",
    "sns.pairplot(data=data)\n",
    "sns.color_palette(\"mako\", as_cmap=True)\n",
    "plt.suptitle(\"Paired Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Year Start'] = data['Year Start'].astype(int)\n",
    "data['Year End'] = data['Year End'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time Interval (years)'] = data['Year End'] - data['Year Start']\n",
    "data['Relative Position (km)'] = data['Vinfinity (km/s)'] * data['Time Interval (years)'] * 365 * 24 * 3600\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D scatter plot\n",
    "fig = px.scatter_3d(data, \n",
    "                     x='relative_position_x', \n",
    "                     y='relative_position_y', \n",
    "                     z='relative_position_z', \n",
    "                     color='Object Designation',  # Use your appropriate column name for designation\n",
    "                     title='Relative Positions of Asteroids',\n",
    "                     labels={'relative_position_x': 'X Position (m)',\n",
    "                             'relative_position_y': 'Y Position (m)',\n",
    "                             'relative_position_z': 'Z Position (m)'},\n",
    "                     hover_name='Object Designation',  # This will show designation on hover\n",
    "                     size_max=10)  # Adjust size_max as necessary\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Close Orbital Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure correct dtype\n",
    "data['i'] = pd.to_numeric(data['i'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_position(x, y, z, vx, vy, vz, time):\n",
    "    return x + vx * time, y + vy * time, z + vz * time\n",
    "\n",
    "data['vx'] = data['Vinfinity (km/s)'] * np.cos(np.radians(data['i']))\n",
    "data['vy'] = data['Vinfinity (km/s)'] * np.sin(np.radians(data['i']))\n",
    "data['vz'] = 0  # Simplified assumption; adjust as necessary\n",
    "\n",
    "def close_approach_analysis(data, threshold_distance=451234123953, time_interval=5):\n",
    "    close_approaches = []\n",
    "    min_year = data['Year Start'].min()\n",
    "    max_year = data['Year End'].max()\n",
    "\n",
    "    # Check only a subset of time steps\n",
    "    time_steps = range(min_year, max_year, time_interval)\n",
    "\n",
    "    # Iterate over all pairs of objects\n",
    "    for i, j in combinations(data.index, 2):\n",
    "        for year in time_steps:\n",
    "            t_i = year - data.loc[i, 'Year Start']\n",
    "            t_j = year - data.loc[j, 'Year Start']\n",
    "\n",
    "            # Predict positions\n",
    "            x1, y1, z1 = predict_position(data.loc[i, 'relative_position_x'], data.loc[i, 'relative_position_y'], data.loc[i, 'relative_position_z'],\n",
    "                                          data.loc[i, 'vx'], data.loc[i, 'vy'], data.loc[i, 'vz'],\n",
    "                                          t_i)\n",
    "            x2, y2, z2 = predict_position(data.loc[j, 'relative_position_x'], data.loc[j, 'relative_position_y'], data.loc[j, 'relative_position_z'],\n",
    "                                          data.loc[j, 'vx'], data.loc[j, 'vy'], data.loc[j, 'vz'],\n",
    "                                          t_j)\n",
    "\n",
    "            # Calculate distance\n",
    "            dist = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2 + (z1 - z2) ** 2)\n",
    "\n",
    "            # Check if distance is below the threshold\n",
    "            if dist < threshold_distance:\n",
    "                close_approaches.append((data.loc[i, 'Object Designation'], data.loc[j, 'Object Designation'], year, dist))\n",
    "    \n",
    "    #         checking for finding threshold value (if needed)\n",
    "    #         print(f'Checking pair: {data.loc[i, \"Object Designation\"]} and {data.loc[j, \"Object Designation\"]}')\n",
    "    #         print(f'Positions: {x1}, {y1}, {z1} and {x2}, {y2}, {z2}')\n",
    "    #         print(f'Distance: {dist}')\n",
    "\n",
    "    return close_approaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes atmost 8 mins\n",
    "close_approaches = close_approach_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_approach_data = pd.DataFrame(close_approaches, columns=['Object 1', 'Object 2', 'Year (approx.)', 'Distance (approx.)'])\n",
    "print(close_approach_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Risk Label'] = (data['Impact Probability (cumulative)'] > 4.00000e-07).astype(int)  # spproximate threshold\n",
    "data = pd.get_dummies(data, drop_first=True)  # Convert categorical variables to dummy variables\n",
    "X = data[['Vinfinity (km/s)', 'Estimated Diameter (km)', 'Impact Probability (cumulative)']]  # Features\n",
    "y = data['Risk Label']  # Labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_true=y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'Vinfinity (km/s)': [5.0],\n",
    "    'Estimated Diameter (km)': [0.051],\n",
    "    'Impact Probability (cumulative)': [3.000000e-07]\n",
    "})\n",
    "new_data.fillna(data.mean(), inplace=True)  # Fill missing values\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Risk Level:\", prediction)  # 0 = low risk, 1 = high risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Incorrect', 'Correct'], \n",
    "            yticklabels=['Incorrect', 'Correct'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
    "plt.xticks(range(X.shape[1]), np.array(['Vinfinity (km/s)', 'Estimated Diameter (km)', 'Impact Probability (cumulative)'])[indices], rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Year Start' to datetime \n",
    "data['Year Start'] = pd.to_datetime(data['Year Start'], format='%Y')\n",
    "\n",
    "# Count close approaches by year\n",
    "trend_data = data.groupby(data['Year Start'].dt.year)['Potential Impacts'].sum()\n",
    "\n",
    "# Plot the trend\n",
    "plt.figure(figsize=(10, 6))\n",
    "trend_data.plot(kind='line', marker='o')\n",
    "plt.title('Trend of Close Approaches Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Close Approaches')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on orbital elements (K-mmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for clustering\n",
    "features = data[['Vinfinity (km/s)','Estimated Diameter (km)']]  # Adjust columns as necessary\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "inertia = []\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Calculate the differences in inertia\n",
    "inertia_diff = np.diff(inertia)\n",
    "\n",
    "# Find the index of the maximum change\n",
    "elbow_index = np.argmax(np.diff(inertia_diff)) + 1  \n",
    "\n",
    "# Get the corresponding number of clusters\n",
    "optimal_k = k_values[elbow_index]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal number of clusters (elbow): {optimal_k}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K-Means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)  \n",
    "data['Cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Plotting the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=data, x='Estimated Diameter (km)', y='Vinfinity (km/s)', hue='Cluster', palette='Set1')\n",
    "plt.title('Clustering of Asteroids based on Diameter and Velocity')\n",
    "plt.xlabel('Estimated Diameter (km)')\n",
    "plt.ylabel('Vinfinity (km/s)')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
